{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# load IMDB dataset\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-classification model to use with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000\n",
    "max_len = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/sidparmar/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/sidparmar/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train ,maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128,\n",
    "                           input_length=max_len,\n",
    "                           name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(), loss=losses.binary_crossentropy, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start using TensorBoard, you need to create a directory where youâ€™ll store the log files it generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='my_log_dir',\n",
    "        histogram_freq=1,\n",
    "        embeddings_freq=1,\n",
    "    ),\n",
    "    \n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='acc',\n",
    "        patience=5\n",
    "    ),\n",
    "    \n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='imdb_with_tensorboard_and_callbacks.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 20s 126ms/step - loss: 0.0905 - acc: 0.9929 - val_loss: 1.2292 - val_acc: 0.8674\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.0947 - acc: 0.9920 - val_loss: 1.2404 - val_acc: 0.8712\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 20s 125ms/step - loss: 0.0908 - acc: 0.9922 - val_loss: 1.2382 - val_acc: 0.8664\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 21s 132ms/step - loss: 0.0894 - acc: 0.9927 - val_loss: 1.2396 - val_acc: 0.8688\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 20s 127ms/step - loss: 0.0909 - acc: 0.9931 - val_loss: 1.2951 - val_acc: 0.8676\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 20s 126ms/step - loss: 0.0872 - acc: 0.9939 - val_loss: 1.2835 - val_acc: 0.8660\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 20s 125ms/step - loss: 0.0910 - acc: 0.9923 - val_loss: 1.2656 - val_acc: 0.8692\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.0872 - acc: 0.9931 - val_loss: 1.3530 - val_acc: 0.8614\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.0898 - acc: 0.9929 - val_loss: 1.2898 - val_acc: 0.8672\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.0895 - acc: 0.9931 - val_loss: 1.3992 - val_acc: 0.8572\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 20s 127ms/step - loss: 0.8845 - acc: 0.5701 - val_loss: 0.4326 - val_acc: 0.8368\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 20s 129ms/step - loss: 0.4294 - acc: 0.8453 - val_loss: 0.4148 - val_acc: 0.8594\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 20s 128ms/step - loss: 0.3600 - acc: 0.8827 - val_loss: 0.4814 - val_acc: 0.8588\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 20s 127ms/step - loss: 0.3291 - acc: 0.9033 - val_loss: 0.7149 - val_acc: 0.8338\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.3042 - acc: 0.9201 - val_loss: 0.5964 - val_acc: 0.8660\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 20s 125ms/step - loss: 0.2238 - acc: 0.9499 - val_loss: 0.5985 - val_acc: 0.8670\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.1956 - acc: 0.9569 - val_loss: 0.8732 - val_acc: 0.8522\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.1457 - acc: 0.9755 - val_loss: 0.9387 - val_acc: 0.8462\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.1377 - acc: 0.9814 - val_loss: 0.8201 - val_acc: 0.8660\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 20s 126ms/step - loss: 0.1197 - acc: 0.9859 - val_loss: 0.8768 - val_acc: 0.8670\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.0847 - acc: 0.9906 - val_loss: 0.9640 - val_acc: 0.8642\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 20s 127ms/step - loss: 0.1133 - acc: 0.9879 - val_loss: 1.0015 - val_acc: 0.8672\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.1147 - acc: 0.9907 - val_loss: 1.0548 - val_acc: 0.8664\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.0953 - acc: 0.9908 - val_loss: 1.1351 - val_acc: 0.8650\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.0977 - acc: 0.9899 - val_loss: 1.1419 - val_acc: 0.8662\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 20s 127ms/step - loss: 0.0820 - acc: 0.9926 - val_loss: 1.1665 - val_acc: 0.8648\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 21s 135ms/step - loss: 0.0917 - acc: 0.9926 - val_loss: 1.1770 - val_acc: 0.8650\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.0872 - acc: 0.9932 - val_loss: 1.1373 - val_acc: 0.8684\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 21s 135ms/step - loss: 0.0775 - acc: 0.9914 - val_loss: 1.2487 - val_acc: 0.8646\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.1014 - acc: 0.9899 - val_loss: 1.6582 - val_acc: 0.8358\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.TensorBoard(\n",
    "#         log_dir='my_log_dir',\n",
    "#         histogram_freq=1,\n",
    "#         embeddings_freq=1,\n",
    "#     )\n",
    "# ]\n",
    "# history = model.fit(x_train, y_train,\n",
    "#                     epochs=20,\n",
    "#                     batch_size=128,\n",
    "#                     validation_split=0.2,\n",
    "#                     callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
